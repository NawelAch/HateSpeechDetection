{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11438013,"sourceType":"datasetVersion","datasetId":7164711}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q evaluate\n\n# 📚 Imports\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom datasets import Dataset, DatasetDict\nfrom sklearn.model_selection import StratifiedKFold\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    DataCollatorWithPadding,\n    TrainingArguments,\n    Trainer,\n    EarlyStoppingCallback\n)\nimport evaluate\nimport os\n\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n\n# 📄 Load dataset\ndf = pd.read_csv(\"/kaggle/input/final-dataset/clean_dataset.csv\")\ndf = df[['X', 'label']].rename(columns={'X': 'comment'})\ndf = df[df['comment'].notnull()]\ndf = df[pd.to_numeric(df['label'], errors='coerce').notnull()]\ndf['label'] = df['label'].astype(int)\ndf['comment'] = df['comment'].astype(str)\ndf = df.reset_index(drop=True)\n\n# 🔤 Tokenizer\nmodel_name = \"UBC-NLP/MARBERTv2\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\ndef tokenize_function(examples):\n    return tokenizer(examples[\"comment\"], truncation=True, padding=True, max_length=256)\n\n# 📏 Metrics\naccuracy = evaluate.load(\"accuracy\")\nf1 = evaluate.load(\"f1\")\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = torch.argmax(torch.tensor(logits), dim=1)\n    acc = accuracy.compute(predictions=preds, references=labels)[\"accuracy\"]\n    f1_score = f1.compute(predictions=preds, references=labels, average=\"weighted\")[\"f1\"]\n    return {\"accuracy\": acc, \"f1\": f1_score}\n\n# 🧩 Data collator\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\n# 🔁 Stratified K-Fold Cross-Validation\nk_folds = 5\nskf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\nall_fold_results = []\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(df, df['label'])):\n    print(f\"\\n🚀 Fold {fold+1}/{k_folds}\")\n\n    # 🗂️ Prepare datasets\n    train_df = df.iloc[train_idx]\n    val_df = df.iloc[val_idx]\n\n    train_dataset = Dataset.from_pandas(train_df)\n    val_dataset = Dataset.from_pandas(val_df)\n\n    dataset = DatasetDict({\n        'train': train_dataset,\n        'test': val_dataset\n    })\n\n    tokenized_dataset = dataset.map(tokenize_function, batched=True)\n\n    # ⚙️ Training arguments\n    training_args = TrainingArguments(\n        output_dir=f\"./fold_{fold+1}\",\n        eval_strategy=\"epoch\",\n        save_strategy=\"epoch\",\n        save_total_limit=1,  # ✅ keep only the best checkpoint\n        load_best_model_at_end=True,\n        metric_for_best_model=\"f1\",\n        greater_is_better=True,\n        learning_rate=3e-6,\n        per_device_train_batch_size=8,\n        per_device_eval_batch_size=8,\n        num_train_epochs=8,\n        weight_decay=0.05,\n        label_smoothing_factor=0.1,\n        gradient_accumulation_steps=2,\n        fp16=True,\n        warmup_steps=300,\n        lr_scheduler_type=\"cosine\",\n        logging_dir=f\"./logs/fold_{fold+1}\",\n        logging_steps=10,\n        push_to_hub=False\n    )\n\n    # 🧠 Load fresh model\n    model = AutoModelForSequenceClassification.from_pretrained(\n        model_name,\n        num_labels=2,\n        id2label={0: \"not_hate\", 1: \"hate\"},\n        label2id={\"not_hate\": 0, \"hate\": 1}\n    )\n    model.gradient_checkpointing_enable()\n\n    # 🏋️‍♂️ Trainer\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=tokenized_dataset[\"train\"],\n        eval_dataset=tokenized_dataset[\"test\"],\n        tokenizer=tokenizer,\n        data_collator=data_collator,\n        compute_metrics=compute_metrics\n        #callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n    )\n\n    trainer.train()\n\n    # 📊 Evaluation\n    result = trainer.evaluate()\n    print(f\"📊 Fold {fold+1} Results:\", result)\n    all_fold_results.append(result)\n\n    # 💾 Save best model (after early stopping & best model restored)\n    best_model_dir = f\"./best_model_fold_{fold+1}\"\n    trainer.save_model(best_model_dir)\n    print(f\"✅ Best model saved to {best_model_dir}\")\n\n# 📈 Final average metrics\navg_accuracy = np.mean([r['eval_accuracy'] for r in all_fold_results])\navg_f1 = np.mean([r['eval_f1'] for r in all_fold_results])\n\nprint(f\"\\n✅ Average Accuracy over {k_folds} folds: {avg_accuracy:.4f}\")\nprint(f\"✅ Average F1 Score over {k_folds} folds: {avg_f1:.4f}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T20:24:31.899421Z","iopub.execute_input":"2025-04-20T20:24:31.899598Z"}},"outputs":[],"execution_count":null}]}