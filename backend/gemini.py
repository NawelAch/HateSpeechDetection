import re
import google.generativeai as genai
from typing import Dict

# Configure the model with explicit safety settings
genai.configure(api_key="AIzaSyBYj1F3wJt-2TYYFC8WQ61ETdScLz54Oa4")
model = genai.GenerativeModel(
    'gemini-1.5-flash',  # Changed to Gemini Flash 1.5
    generation_config={
        'temperature': 0.3,
        'max_output_tokens': 100
    },
    safety_settings={
        'HARM_CATEGORY_HATE_SPEECH': 'BLOCK_NONE',
        'HARM_CATEGORY_DANGEROUS_CONTENT': 'BLOCK_NONE'
    }
)

# def predict_hate_category(text: str) -> Dict[str, str]:
#     """
#     Predicts hate speech category for Arabic text with improved parsing
#     Returns: {'category': '...', 'confidence': float}
#     """
#     # Structured prompt with forced response format
#     prompt = f"""\
# Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ ØµÙ†ÙÙ‡ ÙÙŠ ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø· Ù…Ù† Ù‡Ø°Ù‡ Ø§Ù„ÙØ¦Ø§Øª:
# [Ø¹Ù†ØµØ±ÙŠØ©ØŒ Ø¹Ù†ÙØŒ ÙƒØ±Ø§Ù‡ÙŠØ© Ø§Ù„Ù†Ø³Ø§Ø¡ØŒ Ø¥Ø³Ø§Ø¡Ø©ØŒ Ø±Ù‡Ø§Ø¨ Ø§Ù„Ù…Ø«Ù„ÙŠØ©ØŒ Ø³ÙŠØ§Ø³ÙŠØ©]

# Ø§Ù„Ù…Ø·Ù„ÙˆØ¨:
# 1. Ø§Ø³Ù… Ø§Ù„ÙØ¦Ø© Ø¨Ø§Ù„Ø¶Ø¨Ø· ÙƒÙ…Ø§ ÙÙŠ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©
# 2. Ù†Ø³Ø¨Ø© Ø§Ù„Ø«Ù‚Ø© Ø¨ÙŠÙ† 0-100

# Ù…Ø«Ø§Ù„ Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø©:
# Ø§Ù„ÙØ¦Ø©: Ø¹Ù†ØµØ±ÙŠØ©
# Ø§Ù„Ø«Ù‚Ø©: 95%

# Ø§Ù„Ù†Øµ: "{text}"
# """
    
#     try:
#         response = model.generate_content(prompt)
#         output = response.text.strip()
#         print(f"ğŸ” Raw Response: {output}")

#         # Normalize Arabic/English digits and symbols
#         arabic_to_latin = str.maketrans('Ù Ù¡Ù¢Ù£Ù¤Ù¥Ù¦Ù§Ù¨Ù©Ùª', '0123456789%')
#         normalized = output.translate(arabic_to_latin)
        
#         # Strict regex pattern for category and confidence
#         category_match = re.search(
#             r'Ø§Ù„ÙØ¦Ø©:\s*([^\n]+)', 
#             normalized, 
#             re.IGNORECASE
#         )
        
#         confidence_match = re.search(
#             r'Ø§Ù„Ø«Ù‚Ø©:\s*(\d+\.?\d*)%?', 
#             normalized, 
#             re.IGNORECASE
#         )

#         # Valid categories mapping
#         CATEGORY_MAP = {
#             "Ø¹Ù†ØµØ±ÙŠØ©": "racism",
#             "Ø¹Ù†Ù": "violence",
#             "ÙƒØ±Ø§Ù‡ÙŠØ© Ø§Ù„Ù†Ø³Ø§Ø¡": "misogyny",
#             "Ø¥Ø³Ø§Ø¡Ø©": "offensive",
#             "Ø±Ù‡Ø§Ø¨ Ø§Ù„Ù…Ø«Ù„ÙŠØ©": "homophobia",
#             "Ø³ÙŠØ§Ø³ÙŠØ©": "political"
#         }

#         if category_match and confidence_match:
#             ar_category = category_match.group(1).strip()
#             confidence = min(100, max(0, float(confidence_match.group(1))))
            
#             return {
#                 "category": CATEGORY_MAP.get(ar_category, "unknown"),
#                 "confidence": confidence
#             }

#         # Fallback: Check for any category mention
#         for ar_cat in CATEGORY_MAP:
#             if ar_cat in normalized:
#                 return {
#                     "category": CATEGORY_MAP[ar_cat],
#                     "confidence": 75.0  # Default confidence
#                 }

#         return {"category": "unknown", "confidence": None}

#     except Exception as e:
#         print(f"âš ï¸ Error: {str(e)}")
#         return {"category": "error", "confidence": None}
def predict_hate_category(text: str) -> Dict[str, str]:
    """
    Predicts hate speech category for Arabic text with improved parsing
    Returns: {'category': '...', 'confidence': float}
    """
    prompt = f"""\ 
Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ ØµÙ†ÙÙ‡ ÙÙŠ ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø· Ù…Ù† Ù‡Ø°Ù‡ Ø§Ù„ÙØ¦Ø§Øª:
[Ø¹Ù†ØµØ±ÙŠØ©ØŒ Ø¹Ù†ÙØŒ ÙƒØ±Ø§Ù‡ÙŠØ© Ø§Ù„Ù†Ø³Ø§Ø¡ØŒ Ø¥Ø³Ø§Ø¡Ø©ØŒ Ø±Ù‡Ø§Ø¨ Ø§Ù„Ù…Ø«Ù„ÙŠØ©ØŒ Ø³ÙŠØ§Ø³ÙŠØ©]

Ø§Ù„Ù…Ø·Ù„ÙˆØ¨:
1. Ø§Ø³Ù… Ø§Ù„ÙØ¦Ø© Ø¨Ø§Ù„Ø¶Ø¨Ø· ÙƒÙ…Ø§ ÙÙŠ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©
2. Ù†Ø³Ø¨Ø© Ø§Ù„Ø«Ù‚Ø© Ø¨ÙŠÙ† 0-100

Ù…Ø«Ø§Ù„ Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø©:
Ø§Ù„ÙØ¦Ø©: Ø¹Ù†ØµØ±ÙŠØ©
Ø§Ù„Ø«Ù‚Ø©: 95%

Ø§Ù„Ù†Øµ: "{text}"
"""
    
    try:
        response = model.generate_content(prompt)
        output = response.text.strip()
        print(f"ğŸ” Raw Gemini Output:\n{output}")

        # Normalize Arabic digits and symbols
        arabic_to_latin = str.maketrans('Ù Ù¡Ù¢Ù£Ù¤Ù¥Ù¦Ù§Ù¨Ù©Ùª', '0123456789%')
        normalized = output.translate(arabic_to_latin)

        CATEGORY_MAP = {
            "Ø¹Ù†ØµØ±ÙŠØ©": "racism",
            "Ø¹Ù†Ù": "violence",
            "ÙƒØ±Ø§Ù‡ÙŠØ© Ø§Ù„Ù†Ø³Ø§Ø¡": "misogyny",
            "Ø¥Ø³Ø§Ø¡Ø©": "offensive",
            "Ø±Ù‡Ø§Ø¨ Ø§Ù„Ù…Ø«Ù„ÙŠØ©": "homophobia",
            "Ø³ÙŠØ§Ø³ÙŠØ©": "political"
        }

        # Try strict matching
        category_match = re.search(r'Ø§Ù„ÙØ¦Ø©:\s*([^\n]+)', normalized)
        confidence_match = re.search(r'Ø§Ù„Ø«Ù‚Ø©:\s*(\d+\.?\d*)%?', normalized)

        if category_match and confidence_match:
            ar_category = category_match.group(1).strip()
            confidence = min(100, max(0, float(confidence_match.group(1))))
            return {
                "category": CATEGORY_MAP.get(ar_category, "unknown"),
                "confidence": confidence
            }

        # Fallback if strict match failed
        for ar_cat, en_cat in CATEGORY_MAP.items():
            if ar_cat in normalized:
                print(f"âš¡ Detected Category by fallback: {ar_cat}")
                return {
                    "category": en_cat,
                    "confidence": 75.0  # Assume 75% if not specified
                }

        print("âš ï¸ No category detected.")
        return {"category": "unknown", "confidence": None}

    except Exception as e:
        print(f"âš ï¸ Error: {str(e)}")
        return {"category": "error", "confidence": None}